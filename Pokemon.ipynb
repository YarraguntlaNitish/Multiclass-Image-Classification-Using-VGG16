{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokemon.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dFSTYMGcwPW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "114308c2-d061-445c-fd09-cc9c8f8a7c94"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "#!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "#!apt-get update -qq 2>&1 > /dev/null\n",
        "#!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "--2018-10-31 07:27:42--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpad.net (launchpad.net)... 91.189.89.222, 91.189.89.223\n",
            "Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://launchpadlibrarian.net/386846978/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb [following]\n",
            "--2018-10-31 07:27:44--  https://launchpadlibrarian.net/386846978/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpadlibrarian.net (launchpadlibrarian.net)... 91.189.89.228, 91.189.89.229\n",
            "Connecting to launchpadlibrarian.net (launchpadlibrarian.net)|91.189.89.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1232624 (1.2M) [application/x-debian-package]\n",
            "Saving to: ‘google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.4’\n",
            "\n",
            "google-drive-ocamlf 100%[===================>]   1.17M   778KB/s    in 1.5s    \n",
            "\n",
            "2018-10-31 07:27:47 (778 KB/s) - ‘google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.4’ saved [1232624/1232624]\n",
            "\n",
            "(Reading database ... 22311 files and directories currently installed.)\n",
            "Preparing to unpack google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1) over (0.7.0-0ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A_x1pqkWxxNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ea79537-dcde-423c-9095-cde411670023"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5AxQf2Qv6Zvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73e3a414-aec1-4b1f-b247-c5fa111004c6"
      },
      "cell_type": "code",
      "source": [
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AVvBlf64AiEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WXfntXFbAmwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be3e72d9-6676-4dff-f168-56bb7fd327a0"
      },
      "cell_type": "code",
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('drive/deeplearning/pokeman_dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('drive/deeplearning/pokeman_dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 445 images belonging to 3 classes.\n",
            "Found 238 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ivkJVe8IBHDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaqvH1_mD4ev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTYwuP-uD5en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55928aad-3f29-449a-d367-d97bfde51aa5"
      },
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        "include_top=False,\n",
        "input_shape=(150, 150, 3))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fTdIyEeSD-0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "import os\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eY0O3lq_EOKF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False #do not train the conv-base"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSgknd3QEUO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir = 'drive/deeplearning/pokeman_dataset'\n",
        "train_dir = os.path.join(base_dir, 'training_set')\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test_set')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jpDSJoDEhhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2vacMmgEmXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ac480fa-2ebb-4c6c-871f-c54c3699de1e"
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, \n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='categorical')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 445 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21cgFmlJErk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dd4d84b-b271-4667-c8be-851122e74866"
      },
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150, 150),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 238 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I_DnhITIE3WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HqCPkOX2E7Ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "aa8016ac-5974-4d83-ee0c-58499e22154e"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  8/100 [=>............................] - ETA: 1:45 - loss: 1.0339 - acc: 0.4313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:872: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 162s 2s/step - loss: 0.6840 - acc: 0.7640 - val_loss: 0.4632 - val_acc: 0.8770\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 122s 1s/step - loss: 0.3641 - acc: 0.8960 - val_loss: 0.3301 - val_acc: 0.8931\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 127s 1s/step - loss: 0.2608 - acc: 0.9230 - val_loss: 0.2874 - val_acc: 0.8841\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.2142 - acc: 0.9440 - val_loss: 0.2484 - val_acc: 0.9254\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 121s 1s/step - loss: 0.1749 - acc: 0.9450 - val_loss: 0.2259 - val_acc: 0.9083\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 129s 1s/step - loss: 0.1643 - acc: 0.9490 - val_loss: 0.2083 - val_acc: 0.9173\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.1352 - acc: 0.9650 - val_loss: 0.1916 - val_acc: 0.9224\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 121s 1s/step - loss: 0.1331 - acc: 0.9640 - val_loss: 0.1879 - val_acc: 0.9315\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 129s 1s/step - loss: 0.1061 - acc: 0.9745 - val_loss: 0.1815 - val_acc: 0.9304\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.0967 - acc: 0.9745 - val_loss: 0.2089 - val_acc: 0.9254\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 123s 1s/step - loss: 0.0860 - acc: 0.9770 - val_loss: 0.1674 - val_acc: 0.9345\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 130s 1s/step - loss: 0.0805 - acc: 0.9795 - val_loss: 0.1604 - val_acc: 0.9496\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.0753 - acc: 0.9800 - val_loss: 0.1696 - val_acc: 0.9325\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 122s 1s/step - loss: 0.0622 - acc: 0.9870 - val_loss: 0.1740 - val_acc: 0.9345\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 130s 1s/step - loss: 0.0665 - acc: 0.9795 - val_loss: 0.1728 - val_acc: 0.9315\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.0676 - acc: 0.9815 - val_loss: 0.1606 - val_acc: 0.9264\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 122s 1s/step - loss: 0.0499 - acc: 0.9905 - val_loss: 0.1625 - val_acc: 0.9345\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 133s 1s/step - loss: 0.0519 - acc: 0.9880 - val_loss: 0.1325 - val_acc: 0.9415\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 123s 1s/step - loss: 0.0463 - acc: 0.9885 - val_loss: 0.1466 - val_acc: 0.9435\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 122s 1s/step - loss: 0.0433 - acc: 0.9915 - val_loss: 0.1547 - val_acc: 0.9405\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 134s 1s/step - loss: 0.0463 - acc: 0.9895 - val_loss: 0.1694 - val_acc: 0.9264\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.0433 - acc: 0.9885 - val_loss: 0.1554 - val_acc: 0.9365\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 128s 1s/step - loss: 0.0389 - acc: 0.9910 - val_loss: 0.1715 - val_acc: 0.9304\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.0371 - acc: 0.9920 - val_loss: 0.1568 - val_acc: 0.9284\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 123s 1s/step - loss: 0.0369 - acc: 0.9900 - val_loss: 0.1567 - val_acc: 0.9304\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 130s 1s/step - loss: 0.0347 - acc: 0.9905 - val_loss: 0.1748 - val_acc: 0.9274\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.0360 - acc: 0.9910 - val_loss: 0.1453 - val_acc: 0.9304\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.0316 - acc: 0.9940 - val_loss: 0.1856 - val_acc: 0.9284\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 131s 1s/step - loss: 0.0294 - acc: 0.9955 - val_loss: 0.1697 - val_acc: 0.9325\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.0320 - acc: 0.9905 - val_loss: 0.1679 - val_acc: 0.9284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mN2xj3l8E-9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "    \n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sS2et6eW7uG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PT-Fpr8VXBfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "3b4ef05f-0e5b-40f7-803b-dffa53ee091a"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 18/100 [====>.........................] - ETA: 1:20 - loss: 0.0201 - acc: 0.9944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:872: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 137s 1s/step - loss: 0.0170 - acc: 0.9953 - val_loss: 0.0771 - val_acc: 0.9724\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.1514 - val_acc: 0.9536\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 130s 1s/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0553 - val_acc: 0.9859\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 128s 1s/step - loss: 0.0058 - acc: 0.9970 - val_loss: 0.0893 - val_acc: 0.9691\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 123s 1s/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0833 - val_acc: 0.9637\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 132s 1s/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0549 - val_acc: 0.9785\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 128s 1s/step - loss: 0.0015 - acc: 0.9993 - val_loss: 0.0788 - val_acc: 0.9751\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0672 - val_acc: 0.9724\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 132s 1s/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0410 - val_acc: 0.9805\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 129s 1s/step - loss: 7.5645e-04 - acc: 0.9997 - val_loss: 0.0834 - val_acc: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzViQta4XGp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fde26a38-06e3-473f-905b-e14f996a9d78"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('drive/deeplearning/pokeman_dataset/single_prediction/pokemon1.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "training_set.class_indices"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bulbasaur': 0, 'charmander': 1, 'pikachu': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "KO-_dR3NZufR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899e7d2d-48b9-4a13-e449-b091cfdc9c67"
      },
      "cell_type": "code",
      "source": [
        "if int(result[0][0]) == 1:\n",
        "    prediction = 'Bulbasaur'\n",
        "elif int(result[0][1]) == 1:\n",
        "    prediction = 'Charmander'\n",
        "else:\n",
        "    prediction = 'Pikachu'\n",
        "\n",
        "print (prediction)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bulbasaur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kNliQmRpcPjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33b47eb5-d12c-43fc-c33c-2f6145d001dd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('drive/deeplearning/pokeman_dataset/single_prediction/pokemon2.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "if int(result[0][0]) == 1:\n",
        "    prediction = 'Bulbasaur'\n",
        "elif int(result[0][1]) == 1:\n",
        "    prediction = 'Charmander'\n",
        "else:\n",
        "    prediction = 'Pikachu'\n",
        "\n",
        "print (prediction)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charmander\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Xik3FB0ci0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dd204c5-2ee4-421d-baba-127f231fd58b"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('drive/deeplearning/pokeman_dataset/single_prediction/pokemon3.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "if int(result[0][0]) == 1:\n",
        "    prediction = 'Bulbasaur'\n",
        "elif int(result[0][1]) == 1:\n",
        "    prediction = 'Charmander'\n",
        "else:\n",
        "    prediction = 'Pikachu'\n",
        "\n",
        "print (prediction)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pikachu\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}